
# Spam-classification
Spam classification is a critical task in the field of machine learning and natural language processing aiming to automatically identify and filter out unwanted or unsolicited emails. In this project, I explored the application of the glmnet package in R for spam classification. The main challenges in spam classification include the dynamic nature of spam, the emergency of new spamming techniques and the need for algorithms to adapt to elvolving patterns. The dataset used in this analysis consists of email samples labeled as spam (1) 0r not spam (0). The effective preprocessing is fundamental for preparing data for analysis. In the provided R code, several essential steps were undertaken to refine the email dataset: 
1) **Text Lowercasing:** The intial step involved converting the entire email text to lowercase. This standardization was crucial for ensuring uniformity in the dataset. Lowercasing mitigated issues related to case sensitivity, allowing subsequent analyses to focus on the inherent patterns and content rather than variations in letter casing.
2) **Tokenization:** Following lowercasing, the text underwent tokenization using the work_tokenizer. Tokenization involves breaking down the text into individual words or enabling the subsequent analysis to operate on a more granular level. Each token represented a discrete unit, which is essential for capturing the nuances of language in structured manner.
3) **creating vocabulary and document-term matrix(DTM):** The next crucial step involved creating a vocabulary and constrcting a Document-Term Matrix (DTM). The vocabulary is essentially a comprehensive list of unique words present in the dataset. Simultaneously, the DTM quantifies the frequency of each word in every document. This matrix provided a structured representatin of the data, where rows correspond to documents (emails) and columns to individuak words, with the matrix entries reflecting the frequency of each word in the respective documents.

The analysis aimed to uncover the significance of various features, specifically words, in delineating the distinction between spam and legitimate emails. By identifying which words wield more discriminatory power, the feature importanc aspect provided valuable insights into the critical indicators that contribute to the model's decision-making process. Another focal point of the analysis involved delvinf into the model coefficients associated with each feature in the glmet model. Theese coefficients sheded light on the magnitude and direction of the impact that individual words have on the classification outcome. Understanding these coefficients aided in interpreting the relative influence of each feature and contributed to a better comprehension of the underlying dynamics governing the model's predictions. To gauge the effectiveness of the glmet model, the analysis incorporated the construction of a confusion matrix. This matrix provided a detailed breakdown of the model's performance, delineating true positives, true negatives, false positives, and false negatives. From this matrix, overall accuracy emerged as a key metric, encapsulating the model's ability to correctly calssify emails as spam or not. This comprehensive evaluation served as a crucial benchmark for assessing the model's reliability. 

**CHARACTERISTICS OF THE DATASET**
The dataset comprises two files, '0030228_easy_ham.tar.bz2' and '20030228_spam.tar.bz2,' obtained from the public corpus of Apache SpamAssassin (https://spamassassin.apache.org/old/publiccorpus/). This collection consists of 2,500 ham (non-spam) and 500 emails. Notably, numerical values and URLs in the dataset were uniformly transformed into strings 'NUMBER' and 'URL,' repectively. This dataset represents a simplified version of both spam and ham emails. 

**Algorithms Used**
The R code provided utlizes several libraries, cincluding tidyverse for data manipulation, text2vec for text processing, caTools for data splitting, and glmet for building the logistic regression model. The analysis utilized the text2vec package for streamlined text processing. This package efficiently tokenized the text, established a vocabulary, and produced a Document-Term Matrix (DTM). This DTM format was tailored to suit the requirements of the glmnet model, ensuring an effective representation of the text data for subsequent analysis. 
the logistic regression model was executed using the cv_glmet function from the glmnet package. This function conducted cross-validated trainning, ensured robustness, and determined the optimal regularization parameter(lambda). The selection process was guided by the area under the Receiver Operating Characteristic (ROC) curve, emphasizing the model's ability to discriminate between spam and non-spam emails (type.measure="auc"). This approach enhanced the model's precision and adaptability for effective spam classification. 
The model evaluation employed a confusion matrix, offering breakdown of true positives, true negatives, false positives and false negatives. The overall accuracy, a key metric, was computed as the ratio of correct predictions to the total number of predictions. This assessment provided valuable insights into the model's perfomance in distinguishing between different classes. 

<img width="595" alt="Screenshot 2024-09-23 at 17 57 40" src="https://github.com/user-attachments/assets/059b6247-e598-4cb0-853d-fca12684bc21">

The analysis outcomes encmpassed crucial metrics for a holistic evaluation of the glmnet model in spam classification. The model coefficients and feature importance sheded light on the significance of individual features, aiding in the interpretation of its decision-making process. Additionally, the confusion matrix offered a detailed breakdown of true positives (83), true negatives (2), false positives (17), and fasle negatives (498), providing a comprehensive overview of the model's accuracy and potential areas for improvement. Together, these results delivered a robust assessment of the glmnet model's performance in the intricate task spam calssification. 
